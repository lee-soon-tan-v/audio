<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Recorder & Transcribe with Whisper</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 40px;
            max-width: 700px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }

        .subtitle {
            text-align: center;
            color: #6b7280;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-bottom: 30px;
        }

        button {
            padding: 15px 30px;
            font-size: 16px;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        #startBtn {
            background: #22c55e;
            color: white;
        }

        #startBtn:hover:not(:disabled) {
            background: #16a34a;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(34, 197, 94, 0.4);
        }

        #stopBtn {
            background: #ef4444;
            color: white;
        }

        #stopBtn:hover:not(:disabled) {
            background: #dc2626;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(239, 68, 68, 0.4);
        }

        .status {
            text-align: center;
            margin-bottom: 20px;
            padding: 15px;
            border-radius: 10px;
            font-weight: 500;
        }

        .status.idle {
            background: #f3f4f6;
            color: #6b7280;
        }

        .status.recording {
            background: #fee2e2;
            color: #dc2626;
            animation: pulse 1.5s infinite;
        }

        .status.processing {
            background: #fef3c7;
            color: #d97706;
        }

        .status.success {
            background: #d1fae5;
            color: #065f46;
        }

        @keyframes pulse {

            0%,
            100% {
                opacity: 1;
            }

            50% {
                opacity: 0.7;
            }
        }

        .result-box {
            background: #f9fafb;
            border: 2px solid #e5e7eb;
            border-radius: 10px;
            padding: 20px;
            min-height: 150px;
            margin-bottom: 20px;
        }

        .result-box h3 {
            color: #374151;
            margin-bottom: 10px;
            font-size: 16px;
        }

        .transcript-text {
            color: #111827;
            font-size: 18px;
            font-weight: 500;
            line-height: 1.6;
        }

        .audio-player {
            margin-top: 20px;
            width: 100%;
        }

        audio {
            width: 100%;
            border-radius: 10px;
        }

        .recording-indicator {
            display: none;
            align-items: center;
            justify-content: center;
            gap: 10px;
            margin-bottom: 20px;
        }

        .recording-indicator.active {
            display: flex;
        }

        .recording-dot {
            width: 12px;
            height: 12px;
            background: #ef4444;
            border-radius: 50%;
            animation: blink 1s infinite;
        }

        @keyframes blink {

            0%,
            100% {
                opacity: 1;
            }

            50% {
                opacity: 0.3;
            }
        }

        .info {
            background: #dbeafe;
            border-left: 4px solid #3b82f6;
            padding: 15px;
            border-radius: 5px;
            margin-top: 20px;
        }

        .info p {
            color: #1e40af;
            font-size: 14px;
            line-height: 1.5;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: #e5e7eb;
            border-radius: 10px;
            overflow: hidden;
            margin-top: 10px;
            display: none;
        }

        .progress-bar.active {
            display: block;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s ease;
        }

        .warning {
            background: #fef3c7;
            border-left: 4px solid #f59e0b;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }

        .warning p {
            color: #92400e;
            font-size: 13px;
            line-height: 1.5;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>üé§ Voice Recorder & Transcribe</h1>
        <div class="subtitle">Powered by Whisper AI (runs in your browser)</div>

        <div class="warning">
            <p><strong>‚ö†Ô∏è First-time setup:</strong> The Whisper model (~140MB) will download on first use. This may
                take 1-2 minutes. Subsequent uses will be instant!</p>
        </div>

        <div class="status idle" id="status">Ready to record</div>

        <div class="recording-indicator" id="recordingIndicator">
            <div class="recording-dot"></div>
            <span style="color: #ef4444; font-weight: 600;">Recording...</span>
        </div>

        <div class="controls">
            <button id="startBtn">
                <span>üéôÔ∏è</span>
                <span>Start Recording</span>
            </button>
            <button id="stopBtn" disabled>
                <span>‚èπÔ∏è</span>
                <span>Stop Recording</span>
            </button>
        </div>

        <div class="progress-bar" id="progressBar">
            <div class="progress-fill" id="progressFill"></div>
        </div>

        <div class="result-box">
            <h3>üìù Transcript:</h3>
            <p id="transcript" class="transcript-text">Your transcribed text will appear here...</p>
        </div>

        <div class="audio-player" id="audioPlayerContainer" style="display: none;">
            <h3 style="margin-bottom: 10px; color: #374151;">üîä Recorded Audio:</h3>
            <audio id="audioPlayer" controls></audio>
        </div>

        <div class="info">
            <p><strong>How to use:</strong></p>
            <p>1. Click "Start Recording" and allow microphone access</p>
            <p>2. Speak clearly into your microphone</p>
            <p>3. Click "Stop Recording" when done</p>
            <p>4. Wait for AI transcription (runs locally!)</p>
        </div>
    </div>

    <script type="module">
        import { pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';

        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let transcriber = null;

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        const audioPlayer = document.getElementById('audioPlayer');
        const audioPlayerContainer = document.getElementById('audioPlayerContainer');
        const recordingIndicator = document.getElementById('recordingIndicator');
        const progressBar = document.getElementById('progressBar');
        const progressFill = document.getElementById('progressFill');

        // Initialize Whisper model
        async function initTranscriber() {
            if (!transcriber) {
                status.textContent = '‚è≥ Loading Whisper AI model (first time only)...';
                status.className = 'status processing';
                progressBar.classList.add('active');

                try {
                    // Using base model for better accuracy (avoids [SOUND] outputs)
                    transcriber = await pipeline(
                        'automatic-speech-recognition',
                        'Xenova/whisper-base.en',
                        {
                            quantized: true,
                            progress_callback: (progress) => {
                                if (progress.status === 'progress') {
                                    const percent = Math.round(progress.progress);
                                    progressFill.style.width = percent + '%';
                                }
                            }
                        }
                    );

                    progressBar.classList.remove('active');
                    status.textContent = '‚úÖ Model loaded! Ready to record';
                    status.className = 'status success';

                    setTimeout(() => {
                        status.textContent = 'Ready to record';
                        status.className = 'status idle';
                    }, 2000);
                } catch (error) {
                    console.error('Error loading model:', error);
                    status.textContent = '‚ùå Error loading model';
                    status.className = 'status idle';
                    progressBar.classList.remove('active');
                }
            }
        }

        // Start Recording
        startBtn.addEventListener('click', async () => {
            await initTranscriber();

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPlayer.src = audioUrl;
                    audioPlayerContainer.style.display = 'block';
                    stream.getTracks().forEach(track => track.stop());
                    await transcribeAudio(audioBlob);
                };

                mediaRecorder.start();
                startBtn.disabled = true;
                stopBtn.disabled = false;
                status.textContent = 'üî¥ Recording in progress...';
                status.className = 'status recording';
                recordingIndicator.classList.add('active');
                transcript.textContent = 'Recording... speak now!';
                audioPlayerContainer.style.display = 'none';

            } catch (error) {
                console.error('Error accessing microphone:', error);
                alert('Could not access microphone. Please allow microphone permissions.');
            }
        });

        // Stop Recording
        stopBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                startBtn.disabled = false;
                stopBtn.disabled = true;
                status.textContent = '‚è≥ Processing audio...';
                status.className = 'status processing';
                recordingIndicator.classList.remove('active');
                transcript.textContent = 'Transcribing audio with AI, please wait...';
            }
        });

        // Transcribe Audio
        async function transcribeAudio(blob) {
            try {
                status.textContent = 'ü§ñ AI is transcribing your audio...';
                status.className = 'status processing';
                progressBar.classList.add('active');
                progressFill.style.width = '50%';

                const arrayBuffer = await blob.arrayBuffer();
                const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                // Resample to 16kHz mono (Whisper requirement)
                let audioData;
                if (audioBuffer.numberOfChannels === 2) {
                    const left = audioBuffer.getChannelData(0);
                    const right = audioBuffer.getChannelData(1);
                    audioData = new Float32Array(left.length);
                    for (let i = 0; i < left.length; i++) {
                        audioData[i] = (left[i] + right[i]) / 2;
                    }
                } else {
                    audioData = audioBuffer.getChannelData(0);
                }

                progressFill.style.width = '75%';

                // Transcribe with optimized settings to avoid [SOUND] outputs
                const result = await transcriber(audioData, {
                    chunk_length_s: 30,
                    stride_length_s: 5,
                    return_timestamps: false,
                    language: 'english',
                    task: 'transcribe'
                });

                progressFill.style.width = '100%';
                progressBar.classList.remove('active');

                // Clean up the text (remove [SOUND] if any)
                let transcriptText = result.text || 'No speech detected';
                transcriptText = transcriptText.replace(/\[SOUND\]/g, '').trim();

                if (!transcriptText || transcriptText.length === 0) {
                    transcriptText = 'No clear speech detected. Please speak louder and more clearly.';
                }

                transcript.textContent = transcriptText;
                status.textContent = '‚úÖ Transcription complete!';
                status.className = 'status success';

                setTimeout(() => {
                    status.textContent = 'Ready to record';
                    status.className = 'status idle';
                }, 3000);

            } catch (error) {
                console.error('Transcription error:', error);
                transcript.textContent = '‚ùå Error during transcription: ' + error.message;
                status.textContent = '‚ùå Transcription failed';
                status.className = 'status idle';
                progressBar.classList.remove('active');
            }
        }
    </script>
</body>

</html>
